{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/phoenix301123/graph-diffusion-transformer-for-multi-conditional?scriptVersionId=280985356\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"3d4c7407","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:46:12.115328Z","iopub.status.busy":"2025-11-22T15:46:12.115084Z","iopub.status.idle":"2025-11-22T15:47:26.987428Z","shell.execute_reply":"2025-11-22T15:47:26.986657Z"},"papermill":{"duration":74.878734,"end_time":"2025-11-22T15:47:26.988914","exception":false,"start_time":"2025-11-22T15:46:12.11018","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n","Collecting torch_geometric\r\n","  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\r\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\r\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\r\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\r\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\r\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\r\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\r\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\r\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.13.2)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\r\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.1.3)\r\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\r\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.5)\r\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.6.0)\r\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\r\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\r\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.4.0)\r\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.8.0)\r\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.7.0)\r\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.4.1)\r\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.22.0)\r\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\r\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\r\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\r\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\r\n","Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.3.0)\r\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.3.0)\r\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\r\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.4)\r\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.11)\r\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\r\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.10.5)\r\n","Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2025.3.0)\r\n","Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\r\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.3.0)\r\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.4.0)\r\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\r\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\r\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\r\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch_geometric\r\n","  Attempting uninstall: nvidia-nvjitlink-cu12\r\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-curand-cu12\r\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n","  Attempting uninstall: nvidia-cufft-cu12\r\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n","  Attempting uninstall: nvidia-cublas-cu12\r\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n","  Attempting uninstall: nvidia-cusparse-cu12\r\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n","  Attempting uninstall: nvidia-cudnn-cu12\r\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n","  Attempting uninstall: nvidia-cusolver-cu12\r\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n","libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n","pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch_geometric-2.7.0\r\n"]}],"source":["!pip install torch torch_geometric tqdm"]},{"cell_type":"code","execution_count":2,"id":"48343964","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:27.034607Z","iopub.status.busy":"2025-11-22T15:47:27.033779Z","iopub.status.idle":"2025-11-22T15:47:40.053937Z","shell.execute_reply":"2025-11-22T15:47:40.052986Z"},"papermill":{"duration":13.044408,"end_time":"2025-11-22T15:47:40.055516","exception":false,"start_time":"2025-11-22T15:47:27.011108","status":"completed"},"tags":[]},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.datasets import QM9\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.data import Data\n","from torch_geometric.utils import to_dense_batch\n","import numpy as np\n","import os\n","import math\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"id":"8061e130","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.100519Z","iopub.status.busy":"2025-11-22T15:47:40.099594Z","iopub.status.idle":"2025-11-22T15:47:40.104108Z","shell.execute_reply":"2025-11-22T15:47:40.103396Z"},"papermill":{"duration":0.027858,"end_time":"2025-11-22T15:47:40.10534","exception":false,"start_time":"2025-11-22T15:47:40.077482","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {DEVICE}\")"]},{"cell_type":"code","execution_count":4,"id":"4a9f2d6b","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.149265Z","iopub.status.busy":"2025-11-22T15:47:40.149036Z","iopub.status.idle":"2025-11-22T15:47:40.152619Z","shell.execute_reply":"2025-11-22T15:47:40.151962Z"},"papermill":{"duration":0.026677,"end_time":"2025-11-22T15:47:40.153736","exception":false,"start_time":"2025-11-22T15:47:40.127059","status":"completed"},"tags":[]},"outputs":[],"source":["ATOM_TYPES = [6, 7, 8, 9, 0] # C, N, O, F, Mask\n","NUM_NODE_FEATURES = 11\n","NUM_EDGE_FEATURES = 4 # Single, Double, Triple, Aromatic"]},{"cell_type":"code","execution_count":5,"id":"8cedcd14","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.19956Z","iopub.status.busy":"2025-11-22T15:47:40.199305Z","iopub.status.idle":"2025-11-22T15:47:40.203073Z","shell.execute_reply":"2025-11-22T15:47:40.202414Z"},"papermill":{"duration":0.028776,"end_time":"2025-11-22T15:47:40.204367","exception":false,"start_time":"2025-11-22T15:47:40.175591","status":"completed"},"tags":[]},"outputs":[],"source":["HIDDEN_DIM = 128\n","NUM_LAYERS = 4\n","NUM_HEADS = 4\n","BATCH_SIZE = 64\n","EPOCHS = 20\n","LEARNING_RATE = 1e-4\n","MAX_ATOMS = 9"]},{"cell_type":"code","execution_count":6,"id":"056e2ed2","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.248313Z","iopub.status.busy":"2025-11-22T15:47:40.24806Z","iopub.status.idle":"2025-11-22T15:47:40.252731Z","shell.execute_reply":"2025-11-22T15:47:40.252087Z"},"papermill":{"duration":0.028209,"end_time":"2025-11-22T15:47:40.253901","exception":false,"start_time":"2025-11-22T15:47:40.225692","status":"completed"},"tags":[]},"outputs":[],"source":["class SinusoidalPositionEmbeddings(nn.Module):\n","    \"\"\"\n","    Used to embed the diffusion time step (t) into a continuous vector.\n","    \"\"\"\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.dim = dim\n","\n","    def forward(self, time):\n","        half_dim = self.dim // 2\n","        embeddings = math.log(10000) / (half_dim - 1)\n","        embeddings = torch.exp(torch.arange(half_dim, device=time.device) * -embeddings)\n","        embeddings = time[:, None] * embeddings[None, :]\n","        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n","        return embeddings\n"]},{"cell_type":"code","execution_count":7,"id":"94b0287f","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.298474Z","iopub.status.busy":"2025-11-22T15:47:40.297988Z","iopub.status.idle":"2025-11-22T15:47:40.302385Z","shell.execute_reply":"2025-11-22T15:47:40.301861Z"},"papermill":{"duration":0.028062,"end_time":"2025-11-22T15:47:40.303479","exception":false,"start_time":"2025-11-22T15:47:40.275417","status":"completed"},"tags":[]},"outputs":[],"source":["class ConditionEncoder(nn.Module):\n","    \"\"\"\n","    Maps the molecular property (condition) to a high-dimensional embedding.\n","    The condition is a single normalized QM9 property (e.g., U0).\n","    \"\"\"\n","    def __init__(self, condition_dim, hidden_dim):\n","        super().__init__()\n","        self.encoder = nn.Sequential(\n","            nn.Linear(condition_dim, hidden_dim * 2),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim * 2, hidden_dim)\n","        )\n","\n","    def forward(self, condition):\n","        return self.encoder(condition)"]},{"cell_type":"code","execution_count":8,"id":"f71a3b08","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.348536Z","iopub.status.busy":"2025-11-22T15:47:40.34829Z","iopub.status.idle":"2025-11-22T15:47:40.355353Z","shell.execute_reply":"2025-11-22T15:47:40.354715Z"},"papermill":{"duration":0.031645,"end_time":"2025-11-22T15:47:40.356725","exception":false,"start_time":"2025-11-22T15:47:40.32508","status":"completed"},"tags":[]},"outputs":[],"source":["class GraphDiTBlock(nn.Module):\n","    \"\"\"\n","    A conceptual Graph Transformer Block with FiLM conditioning (similar to DiT).\n","    Processes node features and integrates time/condition embeddings.\n","    \"\"\"\n","    def __init__(self, hidden_dim, num_heads, dropout=0.1):\n","        super().__init__()\n","        self.norm1 = nn.LayerNorm(hidden_dim)\n","        self.attn = nn.MultiheadAttention(\n","            embed_dim=hidden_dim, \n","            num_heads=num_heads, \n","            dropout=dropout, \n","            batch_first=True\n","        )\n","        self.norm2 = nn.LayerNorm(hidden_dim)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim * 4),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim * 4, hidden_dim),\n","            nn.Dropout(dropout)\n","        )\n","        self.film_gamma = nn.Linear(hidden_dim, hidden_dim)\n","        self.film_beta = nn.Linear(hidden_dim, hidden_dim)\n","\n","    def forward(self, x, batch_mask, cond_embedding):\n","        gamma = self.film_gamma(cond_embedding)\n","        beta = self.film_beta(cond_embedding)   \n","        x_modulated = x * (1 + gamma[:, None, :]) + beta[:, None, :]\n","        q = k = v = x_modulated\n","        \n","        attn_mask = ~batch_mask\n","        key_padding_mask = ~batch_mask\n","        attn_output, _ = self.attn(\n","            q, k, v, \n","            key_padding_mask=key_padding_mask\n","        )\n","        x = x + attn_output \n","        x_modulated = self.norm2(x)\n","        x_modulated = x_modulated * (1 + gamma[:, None, :]) + beta[:, None, :]\n","        x = x + self.ffn(x_modulated)\n","\n","        return x"]},{"cell_type":"code","execution_count":9,"id":"3502f956","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.401139Z","iopub.status.busy":"2025-11-22T15:47:40.400513Z","iopub.status.idle":"2025-11-22T15:47:40.406638Z","shell.execute_reply":"2025-11-22T15:47:40.405979Z"},"papermill":{"duration":0.029496,"end_time":"2025-11-22T15:47:40.407982","exception":false,"start_time":"2025-11-22T15:47:40.378486","status":"completed"},"tags":[]},"outputs":[],"source":["class GraphDiT(nn.Module):\n","    \"\"\"\n","    The complete Graph Diffusion Transformer Denoiser Model.\n","    \"\"\"\n","    def __init__(self, num_node_features, num_edge_features, hidden_dim, num_layers, num_heads, max_atoms, conditional_dim=1):\n","        super().__init__()\n","        \n","        self.max_atoms = max_atoms\n","        self.hidden_dim = hidden_dim\n","        self.node_embed = nn.Linear(num_node_features, hidden_dim)\n","        self.time_embed = SinusoidalPositionEmbeddings(hidden_dim)\n","        self.cond_encoder = ConditionEncoder(conditional_dim, hidden_dim)\n","\n","        self.transformer_blocks = nn.ModuleList([\n","            GraphDiTBlock(hidden_dim, num_heads) for _ in range(num_layers)\n","        ])\n","        self.final_norm = nn.LayerNorm(hidden_dim)\n","        self.final_projection = nn.Linear(hidden_dim, num_node_features)\n","\n","    def forward(self, x_noisy, t, condition, batch):\n","        x = self.node_embed(x_noisy)\n","        x_dense, batch_mask = to_dense_batch(x, batch) \n","        time_emb = self.time_embed(t)             \n","        cond_emb = self.cond_encoder(condition)     \n","        joint_cond_emb = time_emb + cond_emb\n","        for block in self.transformer_blocks:\n","            x_dense = block(x_dense, batch_mask, joint_cond_emb)\n","        x_dense = self.final_norm(x_dense)\n","        output_dense = self.final_projection(x_dense) \n","        output = output_dense[batch_mask].contiguous()\n","        return output"]},{"cell_type":"code","execution_count":10,"id":"3b477f8e","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.45305Z","iopub.status.busy":"2025-11-22T15:47:40.452422Z","iopub.status.idle":"2025-11-22T15:47:40.463242Z","shell.execute_reply":"2025-11-22T15:47:40.462653Z"},"papermill":{"duration":0.035019,"end_time":"2025-11-22T15:47:40.464372","exception":false,"start_time":"2025-11-22T15:47:40.429353","status":"completed"},"tags":[]},"outputs":[],"source":["class GraphDiffusion(nn.Module):\n","    \"\"\"\n","    Implements the simplified DDPM forward process and training loss.\n","    Operates on a discrete (categorical) noise model for node types (atoms).\n","    The loss is MSE between predicted noise and actual noise (epsilon).\n","    \"\"\"\n","    def __init__(self, model, num_timesteps=1000, beta_start=1e-4, beta_end=2e-2):\n","        super().__init__()\n","        self.model = model\n","        self.num_timesteps = num_timesteps\n","        self.register_buffer(\n","            'betas', torch.linspace(beta_start, beta_end, num_timesteps, dtype=torch.float32)\n","        )\n","        self.register_buffer('alphas', 1.0 - self.betas)\n","        self.register_buffer('alphas_cumprod', torch.cumprod(self.alphas, dim=0))\n","        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(self.alphas_cumprod))\n","        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1.0 - self.alphas_cumprod))\n","\n","    def forward_diffusion(self, x_start, t, noise=None):\n","        \"\"\"\n","        Applies noise to the original node features (x_start).\n","        Assumes continuous features for the sake of simplicity in DDPM framework, \n","        where x is a feature vector.\n","        \"\"\"\n","        if noise is None:\n","            noise = torch.randn_like(x_start)\n","        sqrt_alpha_prod_t = self.sqrt_alphas_cumprod[t].view(-1, 1)\n","        sqrt_one_minus_alpha_prod_t = self.sqrt_one_minus_alphas_cumprod[t].view(-1, 1)\n","        x_noisy = sqrt_alpha_prod_t * x_start + sqrt_one_minus_alpha_prod_t * noise\n","        return x_noisy, noise\n","\n","    def get_loss(self, data):\n","        \"\"\"\n","        The DDPM training objective: predict the noise (epsilon) added.\n","        \"\"\"\n","        x_start = data.x.float()\n","        batch_size = data.y.size(0)\n","        t = torch.randint(0, self.num_timesteps, (batch_size,), device=DEVICE).long()\n","        batch_index = data.batch\n","        t_nodes = t[batch_index]\n","        condition_unnorm = data.y[:, 2].unsqueeze(1).float() # [B, 1]\n","        MEAN, STD = 40.0, 10.0\n","        condition = (condition_unnorm - MEAN) / STD\n","        x_noisy, noise = self.forward_diffusion(x_start, t_nodes)\n","        noise_pred = self.model(x_noisy, t, condition, data.batch)\n","        loss = F.mse_loss(noise_pred, noise, reduction='none')\n","        loss = loss.mean()\n","        \n","        return loss\n","        \n","    @torch.no_grad()\n","    def reverse_diffusion(self, condition, num_nodes, steps=None):\n","        \"\"\"\n","        The DDPM sampling process: Denoises data iteratively from pure noise (x_T) to x_0.\n","        \n","        Args:\n","            condition (torch.Tensor): The normalized property constraint ([1, 1]).\n","            num_nodes (int): The number of nodes (atoms) in the molecule to generate.\n","            steps (int): Number of steps to run the reverse process. Defaults to num_timesteps.\n","        \"\"\"\n","        steps = steps if steps is not None else self.num_timesteps\n","        x_t = torch.randn(num_nodes, NUM_NODE_FEATURES, device=self.betas.device).float()\n","        batch_tensor = torch.zeros(num_nodes, dtype=torch.long, device=self.betas.device)\n","        cond_batch = condition.expand(1, -1) \n","\n","        for t in tqdm(reversed(range(1, steps + 1)), desc=\"Sampling\", total=steps):\n","            time_tensor = torch.tensor([t], device=self.betas.device).long()\n","            noise_pred = self.model(x_t, time_tensor, cond_batch, batch_tensor)\n","            t_idx = t - 1\n","            alpha_t_val = self.alphas[t_idx]\n","            beta_t = self.betas[t_idx]\n","            sqrt_one_minus_alpha_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t_idx]\n","            sqrt_recip_alpha_t = 1.0 / alpha_t_val.sqrt()\n","            mu_t = sqrt_recip_alpha_t * (x_t - beta_t / sqrt_one_minus_alpha_cumprod_t * noise_pred)\n","            if t > 1:\n","                sigma_t = beta_t.sqrt() \n","                z = torch.randn_like(x_t)\n","                x_t = mu_t + sigma_t * z\n","            else:\n","                x_t = mu_t\n","        return x_t.float()"]},{"cell_type":"code","execution_count":11,"id":"22550158","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.508737Z","iopub.status.busy":"2025-11-22T15:47:40.508252Z","iopub.status.idle":"2025-11-22T15:47:40.512136Z","shell.execute_reply":"2025-11-22T15:47:40.511404Z"},"papermill":{"duration":0.027403,"end_time":"2025-11-22T15:47:40.513379","exception":false,"start_time":"2025-11-22T15:47:40.485976","status":"completed"},"tags":[]},"outputs":[],"source":["class QM9PreTransform:\n","    \"\"\"\n","    A pre_transform to discretize node features (atom types) and select target.\n","    This prepares the data for a categorical graph diffusion model.\n","    \"\"\"\n","    def __init__(self, max_atoms):\n","        self.max_atoms = max_atoms\n","        self.atom_types = ATOM_TYPES\n","        \n","    def __call__(self, data: Data) -> Data:\n","        return data"]},{"cell_type":"code","execution_count":12,"id":"52a9621d","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.557891Z","iopub.status.busy":"2025-11-22T15:47:40.557312Z","iopub.status.idle":"2025-11-22T15:47:40.562438Z","shell.execute_reply":"2025-11-22T15:47:40.561859Z"},"papermill":{"duration":0.028921,"end_time":"2025-11-22T15:47:40.563529","exception":false,"start_time":"2025-11-22T15:47:40.534608","status":"completed"},"tags":[]},"outputs":[],"source":["def load_data(root='./data/QM9_DiT'):\n","    print(\"Loading QM9 dataset...\")\n","\n","    transform = QM9PreTransform(max_atoms=MAX_ATOMS)\n","    dataset = QM9(root=root, pre_filter=transform)\n","    train_size = int(0.8 * len(dataset))\n","    val_size = int(0.1 * len(dataset))\n","    test_size = len(dataset) - train_size - val_size\n","    train_dataset = dataset[:train_size]\n","    val_dataset = dataset[train_size:train_size + val_size]\n","    \n","    train_loader = DataLoader(\n","        train_dataset, \n","        batch_size=BATCH_SIZE, \n","        shuffle=True, \n","        num_workers=2, \n","        pin_memory=True\n","    )\n","    val_loader = DataLoader(\n","        val_dataset, \n","        batch_size=BATCH_SIZE, \n","        shuffle=False, \n","        num_workers=2, \n","        pin_memory=True\n","    )\n","    \n","    print(f\"Dataset loaded: {len(dataset)} total samples.\")\n","    print(f\"Train/Val samples: {len(train_dataset)} / {len(val_dataset)}\")\n","    \n","    return train_loader, val_loader"]},{"cell_type":"code","execution_count":13,"id":"036491c3","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.607625Z","iopub.status.busy":"2025-11-22T15:47:40.607399Z","iopub.status.idle":"2025-11-22T15:47:40.615626Z","shell.execute_reply":"2025-11-22T15:47:40.614969Z"},"papermill":{"duration":0.032236,"end_time":"2025-11-22T15:47:40.616943","exception":false,"start_time":"2025-11-22T15:47:40.584707","status":"completed"},"tags":[]},"outputs":[],"source":["def train_model(train_loader, val_loader):\n","    # Initialize Model, Diffusion Process, Optimizer\n","    dit_model = GraphDiT(\n","        num_node_features=NUM_NODE_FEATURES,\n","        num_edge_features=NUM_EDGE_FEATURES,\n","        hidden_dim=HIDDEN_DIM,\n","        num_layers=NUM_LAYERS,\n","        num_heads=NUM_HEADS,\n","        max_atoms=MAX_ATOMS,\n","        conditional_dim=1\n","    ).to(DEVICE)\n","\n","    diffusion_process = GraphDiffusion(dit_model).to(DEVICE)\n","    optimizer = torch.optim.Adam(dit_model.parameters(), lr=LEARNING_RATE)\n","    \n","    print(\"\\nStarting training...\")\n","    \n","    best_val_loss = float('inf')\n","    KAGGLE_SAVE_DIR = '/kaggle/working/checkpoint'\n","    checkpoint_path = os.path.join(KAGGLE_SAVE_DIR, 'best_graph_dit_qm9.pth')\n","    os.makedirs(KAGGLE_SAVE_DIR, exist_ok=True)\n","    for epoch in range(1, EPOCHS + 1):\n","        # Training Phase\n","        dit_model.train()\n","        train_loss_sum = 0\n","        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\", leave=False)\n","        for data in train_pbar:\n","            data = data.to(DEVICE)\n","            if data is None: continue \n","            if data.x.size(0) == 0: continue\n","            data.x = data.x.to(torch.float32)\n","            optimizer.zero_grad()\n","\n","            loss = diffusion_process.get_loss(data)\n","            \n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(dit_model.parameters(), 1.0)\n","            optimizer.step()\n","            \n","            train_loss_sum += loss.item()\n","            train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n","\n","        avg_train_loss = train_loss_sum / len(train_loader)\n","        dit_model.eval()\n","        val_loss_sum = 0\n","        \n","        val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch} [Valid]\", leave=False)\n","        \n","        with torch.no_grad():\n","            for data in val_pbar:\n","                data = data.to(DEVICE)\n","                if data is None: continue\n","                if data.x.size(0) == 0: continue\n","                \n","                loss = diffusion_process.get_loss(data)\n","                val_loss_sum += loss.item()\n","                val_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n","\n","        avg_val_loss = val_loss_sum / len(val_loader)\n","\n","        print(f\"Epoch {epoch}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            torch.save(dit_model.state_dict(), checkpoint_path)\n","            print(f\"-> Saved best model checkpoint to {checkpoint_path} (Val Loss: {best_val_loss:.4f})\")"]},{"cell_type":"code","execution_count":14,"id":"cb778699","metadata":{"execution":{"iopub.execute_input":"2025-11-22T15:47:40.660479Z","iopub.status.busy":"2025-11-22T15:47:40.65998Z","iopub.status.idle":"2025-11-22T16:09:30.477594Z","shell.execute_reply":"2025-11-22T16:09:30.476705Z"},"papermill":{"duration":1309.840918,"end_time":"2025-11-22T16:09:30.479076","exception":false,"start_time":"2025-11-22T15:47:40.638158","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading QM9 dataset...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading https://data.pyg.org/datasets/qm9_v3.zip\n","Extracting data/QM9_DiT/raw/qm9_v3.zip\n","Processing...\n","Using a pre-processed version of the dataset. Please install 'rdkit' to alternatively process the raw data.\n","Done!\n"]},{"name":"stdout","output_type":"stream","text":["Dataset loaded: 130831 total samples.\n","Train/Val samples: 104664 / 13083\n","\n","Starting training...\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20 | Train Loss: 0.0888 | Val Loss: 0.0433\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0433)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/20 | Train Loss: 0.0475 | Val Loss: 0.0336\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0336)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/20 | Train Loss: 0.0417 | Val Loss: 0.0353\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/20 | Train Loss: 0.0383 | Val Loss: 0.0307\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0307)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/20 | Train Loss: 0.0362 | Val Loss: 0.0285\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0285)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/20 | Train Loss: 0.0346 | Val Loss: 0.0291\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 7/20 | Train Loss: 0.0334 | Val Loss: 0.0294\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 8/20 | Train Loss: 0.0321 | Val Loss: 0.0271\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0271)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                               \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 9/20 | Train Loss: 0.0315 | Val Loss: 0.0264\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0264)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 10/20 | Train Loss: 0.0310 | Val Loss: 0.0269\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 11/20 | Train Loss: 0.0305 | Val Loss: 0.0275\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 12/20 | Train Loss: 0.0302 | Val Loss: 0.0264\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 13/20 | Train Loss: 0.0294 | Val Loss: 0.0261\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0261)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 14/20 | Train Loss: 0.0288 | Val Loss: 0.0256\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0256)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 15/20 | Train Loss: 0.0285 | Val Loss: 0.0247\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0247)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 16/20 | Train Loss: 0.0279 | Val Loss: 0.0250\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 17/20 | Train Loss: 0.0276 | Val Loss: 0.0244\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0244)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 18/20 | Train Loss: 0.0274 | Val Loss: 0.0246\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 19/20 | Train Loss: 0.0274 | Val Loss: 0.0243\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0243)\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch 20/20 | Train Loss: 0.0270 | Val Loss: 0.0238\n","-> Saved best model checkpoint to /kaggle/working/checkpoint/best_graph_dit_qm9.pth (Val Loss: 0.0238)\n"]}],"source":["if __name__ == '__main__':\n","    train_loader, val_loader = load_data()\n","    train_model(train_loader, val_loader)"]},{"cell_type":"code","execution_count":15,"id":"9f5f15d1","metadata":{"execution":{"iopub.execute_input":"2025-11-22T16:09:34.766654Z","iopub.status.busy":"2025-11-22T16:09:34.765789Z","iopub.status.idle":"2025-11-22T16:09:34.918346Z","shell.execute_reply":"2025-11-22T16:09:34.917416Z"},"papermill":{"duration":2.442165,"end_time":"2025-11-22T16:09:34.919557","exception":false,"start_time":"2025-11-22T16:09:32.477392","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Checking for cache directory: ./data/QM9_DiT\n","Found cache. Deleting old cache to force full dataset re-processing...\n","Cache deleted. Run the training script now to download the full QM9 dataset (~134k samples).\n"]}],"source":["import os\n","import shutil\n","\n","cache_dir = './data/QM9_DiT' \n","\n","print(f\"Checking for cache directory: {cache_dir}\")\n","if os.path.exists(cache_dir):\n","    print(\"Found cache. Deleting old cache to force full dataset re-processing...\")\n","    shutil.rmtree(cache_dir)\n","    print(\"Cache deleted. Run the training script now to download the full QM9 dataset (~134k samples).\")\n","else:\n","    print(\"Cache directory not found. Proceeding with load.\")"]},{"cell_type":"code","execution_count":16,"id":"2730a6e9","metadata":{"execution":{"iopub.execute_input":"2025-11-22T16:09:39.141068Z","iopub.status.busy":"2025-11-22T16:09:39.140426Z","iopub.status.idle":"2025-11-22T16:09:39.145087Z","shell.execute_reply":"2025-11-22T16:09:39.144528Z"},"papermill":{"duration":2.098541,"end_time":"2025-11-22T16:09:39.146266","exception":false,"start_time":"2025-11-22T16:09:37.047725","status":"completed"},"tags":[]},"outputs":[],"source":["def interpret_continuous_features(x_continuous):\n","    print(\"\\n--- Interpreting Final Denoised Node Features ---\")\n","    num_generated_atoms = len(x_continuous)\n","    atomic_number_feature = x_continuous[:, 0].cpu().numpy()\n","    \n","    print(f\"Number of generated atoms: {len(x_continuous)}\")\n","    print(f\"First Atomic Number features (continuous output): {atomic_number_feature[:(num_generated_atoms)]}\")\n","    suggested_atomic_numbers = np.round(atomic_number_feature).astype(int)\n","    print(f\"First Suggested Atomic Numbers (Rounding the continuous output): {suggested_atomic_numbers[:(num_generated_atoms)]}\")\n","    print(\"These features would need a dedicated classifier/decoder to map to valid discrete molecular structures.\")\n","    \n","    return x_continuous"]},{"cell_type":"code","execution_count":17,"id":"43247745","metadata":{"execution":{"iopub.execute_input":"2025-11-22T16:09:43.321558Z","iopub.status.busy":"2025-11-22T16:09:43.320861Z","iopub.status.idle":"2025-11-22T16:09:43.327231Z","shell.execute_reply":"2025-11-22T16:09:43.326634Z"},"papermill":{"duration":2.104333,"end_time":"2025-11-22T16:09:43.328396","exception":false,"start_time":"2025-11-22T16:09:41.224063","status":"completed"},"tags":[]},"outputs":[],"source":["def sample_molecule(checkpoint_path, target_u0=50.0, num_atoms=9):\n","    \"\"\"\n","    Loads the model and generates a new molecule conditioned on a target U0 energy.\n","    \"\"\"\n","    print(f\"\\n--- Starting Conditional Molecule Sampling ---\")\n","    print(f\"Target property U0: {target_u0} | Generating molecule with {num_atoms} atoms.\")\n","    dit_model = GraphDiT(\n","        num_node_features=NUM_NODE_FEATURES,\n","        num_edge_features=NUM_EDGE_FEATURES,\n","        hidden_dim=HIDDEN_DIM,\n","        num_layers=NUM_LAYERS,\n","        num_heads=NUM_HEADS,\n","        max_atoms=MAX_ATOMS,\n","        conditional_dim=1\n","    ).to(DEVICE)\n","\n","    diffusion_process = GraphDiffusion(dit_model).to(DEVICE) \n","    if not os.path.exists(checkpoint_path):\n","        print(f\"Error: Checkpoint file not found at {checkpoint_path}. Please train the model first.\")\n","        return\n","        \n","    try:\n","        dit_model.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n","        print(f\"Successfully loaded model weights from {checkpoint_path}\")\n","    except Exception as e:\n","        print(f\"Error loading checkpoint: {e}\")\n","        return\n","\n","    dit_model.eval()\n","    MEAN, STD = 40.0, 10.0\n","    condition_unnorm = torch.tensor([[target_u0]], dtype=torch.float32, device=DEVICE)\n","    condition_norm = (condition_unnorm - MEAN) / STD\n","    final_continuous_features = diffusion_process.reverse_diffusion(\n","        condition=condition_norm, \n","        num_nodes=num_atoms\n","    )\n","    interpret_continuous_features(final_continuous_features)\n","    \n","    print(\"\\nSampling complete. The result is the continuous node feature matrix.\")"]},{"cell_type":"code","execution_count":18,"id":"669d5bea","metadata":{"execution":{"iopub.execute_input":"2025-11-22T16:09:47.463859Z","iopub.status.busy":"2025-11-22T16:09:47.463287Z","iopub.status.idle":"2025-11-22T16:09:51.619806Z","shell.execute_reply":"2025-11-22T16:09:51.618864Z"},"papermill":{"duration":6.352274,"end_time":"2025-11-22T16:09:51.621055","exception":false,"start_time":"2025-11-22T16:09:45.268781","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","--- Starting Conditional Molecule Sampling ---\n","Target property U0: 30 | Generating molecule with 4 atoms.\n","Successfully loaded model weights from /kaggle/working/checkpoint/best_graph_dit_qm9.pth\n"]},{"name":"stderr","output_type":"stream","text":["Sampling: 100%|██████████| 1000/1000 [00:04<00:00, 243.50it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","--- Interpreting Final Denoised Node Features ---\n","Number of generated atoms: 4\n","First Atomic Number features (continuous output): [ 0.9934025   0.99875605  0.99524206 -0.04846189]\n","First Suggested Atomic Numbers (Rounding the continuous output): [1 1 1 0]\n","These features would need a dedicated classifier/decoder to map to valid discrete molecular structures.\n","\n","Sampling complete. The result is the continuous node feature matrix.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["CHECKPOINT_PATH = '/kaggle/working/checkpoint/best_graph_dit_qm9.pth'\n","sample_molecule(CHECKPOINT_PATH, target_u0=30, num_atoms=4)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":1428.060624,"end_time":"2025-11-22T16:09:56.486352","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-11-22T15:46:08.425728","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}